{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f229dd-ca28-4810-a01f-430327b4805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df116869-5d2f-4d52-a2f9-29fae5274348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2156fe1-f6a7-4838-83ca-ab755acc6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d741ac-ed8a-41c6-a4a2-1272b403dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b01b3287-656d-41ec-8948-fe75ed8d2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'C')\n",
    "y = df['C']\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y , \n",
    "                                   random_state=104,  \n",
    "                                   test_size=0.25, stratify = y,\n",
    "                                   shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c2af188-66d7-4d84-9740-c80eddd403f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform it\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8dfaf8-d509-464c-908a-86f1eb474fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e52245ee-f7bd-4141-b5e9-7099bc8f8f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u67b4278e5b665e2700363c80698909b/.local/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28618</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14309</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14309</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7155</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7155</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3578</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3578</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3578</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1789</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114496</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,663,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28618\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14309\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14309\u001b[0m, \u001b[38;5;34m256\u001b[0m)     │       \u001b[38;5;34m327,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7155\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7155\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m163,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3578\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3578\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3578\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m41,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1789\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114496\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │     \u001b[38;5;34m3,663,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m231\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,198,599</span> (16.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,198,599\u001b[0m (16.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,198,599</span> (16.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,198,599\u001b[0m (16.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout,Flatten,Dense\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "model=Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "model.add(Dense(units=7, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy', 'precision', 'recall'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3bba484-407c-48e5-94fe-a9c2d52d6663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=7)\n",
    "y_train_one_hot.shape\n",
    "\n",
    "\n",
    "\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=7)\n",
    "y_test_one_hot.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf799704-77ab-446f-8257-094505686bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 564ms/step - accuracy: 0.1759 - loss: 32.5355 - precision: 0.2095 - recall: 0.1230 - val_accuracy: 0.1034 - val_loss: 1.9572 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 559ms/step - accuracy: 0.0918 - loss: 1.9768 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9704 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 564ms/step - accuracy: 0.1242 - loss: 1.9636 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9675 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 570ms/step - accuracy: 0.1172 - loss: 1.9682 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 563ms/step - accuracy: 0.0813 - loss: 1.9685 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9618 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 562ms/step - accuracy: 0.0803 - loss: 1.9682 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9592 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 573ms/step - accuracy: 0.0889 - loss: 1.9626 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9566 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 571ms/step - accuracy: 0.0752 - loss: 1.9636 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9538 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 569ms/step - accuracy: 0.0978 - loss: 1.9518 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9512 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 572ms/step - accuracy: 0.0913 - loss: 1.9575 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9491 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 572ms/step - accuracy: 0.0898 - loss: 1.9505 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9468 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 563ms/step - accuracy: 0.1129 - loss: 1.9465 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9451 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 558ms/step - accuracy: 0.0706 - loss: 1.9502 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9437 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 567ms/step - accuracy: 0.1179 - loss: 1.9468 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9422 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 568ms/step - accuracy: 0.0861 - loss: 1.9477 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9403 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 550ms/step - accuracy: 0.0999 - loss: 1.9427 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9382 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 558ms/step - accuracy: 0.0985 - loss: 1.9388 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.1034 - val_loss: 1.9366 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 562ms/step - accuracy: 0.0904 - loss: 1.9387 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9347 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 562ms/step - accuracy: 0.2786 - loss: 1.9331 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9330 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 562ms/step - accuracy: 0.2997 - loss: 1.9305 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9318 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 555ms/step - accuracy: 0.2723 - loss: 1.9377 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9308 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 557ms/step - accuracy: 0.2645 - loss: 1.9317 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9298 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 559ms/step - accuracy: 0.2626 - loss: 1.9326 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9288 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 565ms/step - accuracy: 0.2314 - loss: 1.9333 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9277 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 555ms/step - accuracy: 0.2958 - loss: 1.9215 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9263 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 552ms/step - accuracy: 0.2800 - loss: 1.9235 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9249 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 560ms/step - accuracy: 0.2506 - loss: 1.9252 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9238 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 557ms/step - accuracy: 0.2489 - loss: 1.9273 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9225 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 550ms/step - accuracy: 0.2600 - loss: 1.9261 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9213 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 557ms/step - accuracy: 0.2412 - loss: 1.9305 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9201 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 554ms/step - accuracy: 0.2756 - loss: 1.9157 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9187 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 559ms/step - accuracy: 0.2480 - loss: 1.9213 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9176 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 559ms/step - accuracy: 0.2818 - loss: 1.9159 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9169 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 559ms/step - accuracy: 0.2827 - loss: 1.9132 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9162 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 557ms/step - accuracy: 0.2696 - loss: 1.9187 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9152 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 567ms/step - accuracy: 0.2476 - loss: 1.9209 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9145 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 558ms/step - accuracy: 0.2828 - loss: 1.9113 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9139 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 560ms/step - accuracy: 0.2560 - loss: 1.9179 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9130 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 561ms/step - accuracy: 0.2705 - loss: 1.9110 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9120 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 559ms/step - accuracy: 0.2704 - loss: 1.9137 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9115 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 557ms/step - accuracy: 0.2850 - loss: 1.9065 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9109 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 550ms/step - accuracy: 0.2715 - loss: 1.9100 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9103 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 563ms/step - accuracy: 0.2777 - loss: 1.9071 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9098 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 562ms/step - accuracy: 0.2831 - loss: 1.9035 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9091 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 567ms/step - accuracy: 0.2510 - loss: 1.9094 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9084 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 558ms/step - accuracy: 0.2291 - loss: 1.9210 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9079 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 558ms/step - accuracy: 0.2834 - loss: 1.9031 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9074 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 553ms/step - accuracy: 0.2724 - loss: 1.9028 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9067 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 560ms/step - accuracy: 0.2886 - loss: 1.8989 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9060 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 555ms/step - accuracy: 0.2411 - loss: 1.9149 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.2644 - val_loss: 1.9056 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x151398a1df90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_std, y_train_one_hot, epochs = 50, validation_data = (X_test_std, y_test_one_hot), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a29ff7-6b70-45fa-98e1-d85c211fa5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 620ms/step - accuracy: 0.2483 - loss: 1.9463 - precision: 0.2667 - recall: 0.0412 - val_accuracy: 0.2759 - val_loss: 1.8262 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 579ms/step - accuracy: 0.3210 - loss: 1.7827 - precision: 0.5993 - recall: 0.0837 - val_accuracy: 0.3448 - val_loss: 1.7595 - val_precision: 0.6667 - val_recall: 0.0690\n",
      "Epoch 3/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 571ms/step - accuracy: 0.3946 - loss: 1.6218 - precision: 0.7503 - recall: 0.1183 - val_accuracy: 0.4483 - val_loss: 1.6595 - val_precision: 0.7692 - val_recall: 0.1149\n",
      "Epoch 4/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 564ms/step - accuracy: 0.5191 - loss: 1.4369 - precision: 0.8629 - recall: 0.2256 - val_accuracy: 0.4828 - val_loss: 1.7261 - val_precision: 0.7500 - val_recall: 0.1724\n",
      "Epoch 5/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 579ms/step - accuracy: 0.5027 - loss: 1.5335 - precision: 0.9077 - recall: 0.2682 - val_accuracy: 0.4943 - val_loss: 1.5920 - val_precision: 0.7241 - val_recall: 0.2414\n",
      "Epoch 6/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 574ms/step - accuracy: 0.5481 - loss: 1.1918 - precision: 0.8875 - recall: 0.3461 - val_accuracy: 0.5632 - val_loss: 1.5395 - val_precision: 0.7045 - val_recall: 0.3563\n",
      "Epoch 7/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 562ms/step - accuracy: 0.6334 - loss: 1.0788 - precision: 0.7756 - recall: 0.4693 - val_accuracy: 0.5287 - val_loss: 1.6317 - val_precision: 0.6190 - val_recall: 0.2989\n",
      "Epoch 8/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 571ms/step - accuracy: 0.6482 - loss: 1.0550 - precision: 0.7946 - recall: 0.4599 - val_accuracy: 0.5402 - val_loss: 1.3969 - val_precision: 0.8214 - val_recall: 0.2644\n",
      "Epoch 9/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 581ms/step - accuracy: 0.6897 - loss: 0.9444 - precision: 0.9356 - recall: 0.4485 - val_accuracy: 0.6437 - val_loss: 1.3480 - val_precision: 0.8095 - val_recall: 0.3908\n",
      "Epoch 10/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 574ms/step - accuracy: 0.7270 - loss: 0.8504 - precision: 0.9071 - recall: 0.5063 - val_accuracy: 0.5747 - val_loss: 1.3358 - val_precision: 0.7308 - val_recall: 0.4368\n",
      "Epoch 11/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 570ms/step - accuracy: 0.6642 - loss: 0.8685 - precision: 0.8303 - recall: 0.5399 - val_accuracy: 0.6782 - val_loss: 1.2204 - val_precision: 0.8113 - val_recall: 0.4943\n",
      "Epoch 12/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 568ms/step - accuracy: 0.7926 - loss: 0.6662 - precision: 0.9081 - recall: 0.6869 - val_accuracy: 0.6552 - val_loss: 1.3340 - val_precision: 0.7656 - val_recall: 0.5632\n",
      "Epoch 13/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 567ms/step - accuracy: 0.7864 - loss: 0.5773 - precision: 0.8821 - recall: 0.7258 - val_accuracy: 0.6322 - val_loss: 1.4576 - val_precision: 0.7576 - val_recall: 0.5747\n",
      "Epoch 14/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 571ms/step - accuracy: 0.7976 - loss: 0.4942 - precision: 0.8944 - recall: 0.7597 - val_accuracy: 0.6782 - val_loss: 1.3002 - val_precision: 0.7910 - val_recall: 0.6092\n",
      "Epoch 15/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 562ms/step - accuracy: 0.8390 - loss: 0.5788 - precision: 0.9205 - recall: 0.7630 - val_accuracy: 0.7126 - val_loss: 1.2761 - val_precision: 0.7500 - val_recall: 0.6207\n",
      "Epoch 16/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 570ms/step - accuracy: 0.8507 - loss: 0.4656 - precision: 0.9093 - recall: 0.7837 - val_accuracy: 0.6782 - val_loss: 1.4487 - val_precision: 0.7639 - val_recall: 0.6322\n",
      "Epoch 17/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 581ms/step - accuracy: 0.8511 - loss: 0.3971 - precision: 0.9247 - recall: 0.7916 - val_accuracy: 0.6782 - val_loss: 1.5992 - val_precision: 0.7206 - val_recall: 0.5632\n",
      "Epoch 18/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 570ms/step - accuracy: 0.8720 - loss: 0.4885 - precision: 0.9179 - recall: 0.8014 - val_accuracy: 0.8046 - val_loss: 2.0580 - val_precision: 0.8052 - val_recall: 0.7126\n",
      "Epoch 19/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 568ms/step - accuracy: 0.9226 - loss: 0.3138 - precision: 0.9315 - recall: 0.8790 - val_accuracy: 0.7356 - val_loss: 1.7251 - val_precision: 0.7692 - val_recall: 0.6897\n",
      "Epoch 20/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 568ms/step - accuracy: 0.8562 - loss: 0.5316 - precision: 0.8913 - recall: 0.8151 - val_accuracy: 0.7586 - val_loss: 1.8799 - val_precision: 0.7821 - val_recall: 0.7011\n",
      "Epoch 21/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 577ms/step - accuracy: 0.8848 - loss: 0.3661 - precision: 0.9146 - recall: 0.8314 - val_accuracy: 0.7241 - val_loss: 2.2280 - val_precision: 0.7632 - val_recall: 0.6667\n",
      "Epoch 22/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 581ms/step - accuracy: 0.9276 - loss: 0.2821 - precision: 0.9562 - recall: 0.8387 - val_accuracy: 0.8276 - val_loss: 2.1073 - val_precision: 0.8537 - val_recall: 0.8046\n",
      "Epoch 23/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 567ms/step - accuracy: 0.8893 - loss: 0.2574 - precision: 0.9089 - recall: 0.8528 - val_accuracy: 0.7471 - val_loss: 1.8013 - val_precision: 0.7711 - val_recall: 0.7356\n",
      "Epoch 24/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 570ms/step - accuracy: 0.9402 - loss: 0.2607 - precision: 0.9597 - recall: 0.9220 - val_accuracy: 0.7586 - val_loss: 1.9135 - val_precision: 0.7711 - val_recall: 0.7356\n",
      "Epoch 25/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 565ms/step - accuracy: 0.9206 - loss: 0.3190 - precision: 0.9359 - recall: 0.8966 - val_accuracy: 0.7816 - val_loss: 1.5351 - val_precision: 0.7901 - val_recall: 0.7356\n",
      "Epoch 26/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 559ms/step - accuracy: 0.9372 - loss: 0.2677 - precision: 0.9529 - recall: 0.9016 - val_accuracy: 0.8161 - val_loss: 1.1589 - val_precision: 0.8272 - val_recall: 0.7701\n",
      "Epoch 27/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 571ms/step - accuracy: 0.9408 - loss: 0.1852 - precision: 0.9619 - recall: 0.9318 - val_accuracy: 0.7701 - val_loss: 1.1165 - val_precision: 0.8205 - val_recall: 0.7356\n",
      "Epoch 28/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 565ms/step - accuracy: 0.9357 - loss: 0.2133 - precision: 0.9521 - recall: 0.9159 - val_accuracy: 0.8046 - val_loss: 1.3585 - val_precision: 0.8049 - val_recall: 0.7586\n",
      "Epoch 29/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 564ms/step - accuracy: 0.9544 - loss: 0.1458 - precision: 0.9696 - recall: 0.9505 - val_accuracy: 0.8161 - val_loss: 1.4665 - val_precision: 0.8333 - val_recall: 0.8046\n",
      "Epoch 30/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 567ms/step - accuracy: 0.9722 - loss: 0.1068 - precision: 0.9857 - recall: 0.9494 - val_accuracy: 0.7931 - val_loss: 1.8104 - val_precision: 0.8049 - val_recall: 0.7586\n",
      "Epoch 31/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 577ms/step - accuracy: 0.9782 - loss: 0.1535 - precision: 0.9789 - recall: 0.9569 - val_accuracy: 0.8276 - val_loss: 1.4865 - val_precision: 0.8462 - val_recall: 0.7586\n",
      "Epoch 32/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 574ms/step - accuracy: 0.9592 - loss: 0.1322 - precision: 0.9600 - recall: 0.9429 - val_accuracy: 0.8391 - val_loss: 1.4672 - val_precision: 0.8554 - val_recall: 0.8161\n",
      "Epoch 33/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 564ms/step - accuracy: 0.9319 - loss: 0.2852 - precision: 0.9455 - recall: 0.9216 - val_accuracy: 0.7816 - val_loss: 1.6350 - val_precision: 0.8228 - val_recall: 0.7471\n",
      "Epoch 34/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 574ms/step - accuracy: 0.9340 - loss: 0.1962 - precision: 0.9464 - recall: 0.9141 - val_accuracy: 0.7701 - val_loss: 1.7648 - val_precision: 0.7683 - val_recall: 0.7241\n",
      "Epoch 35/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 576ms/step - accuracy: 0.9367 - loss: 0.1614 - precision: 0.9561 - recall: 0.9331 - val_accuracy: 0.7816 - val_loss: 1.3788 - val_precision: 0.7805 - val_recall: 0.7356\n",
      "Epoch 36/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 565ms/step - accuracy: 0.9738 - loss: 0.1264 - precision: 0.9792 - recall: 0.9493 - val_accuracy: 0.8736 - val_loss: 1.4157 - val_precision: 0.8675 - val_recall: 0.8276\n",
      "Epoch 37/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 570ms/step - accuracy: 0.9888 - loss: 0.0560 - precision: 0.9886 - recall: 0.9777 - val_accuracy: 0.8621 - val_loss: 1.5248 - val_precision: 0.8675 - val_recall: 0.8276\n",
      "Epoch 38/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 571ms/step - accuracy: 0.9657 - loss: 0.1104 - precision: 0.9708 - recall: 0.9405 - val_accuracy: 0.8391 - val_loss: 1.2006 - val_precision: 0.8684 - val_recall: 0.7586\n",
      "Epoch 39/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 570ms/step - accuracy: 0.9785 - loss: 0.1096 - precision: 0.9906 - recall: 0.9629 - val_accuracy: 0.8621 - val_loss: 1.1208 - val_precision: 0.8690 - val_recall: 0.8391\n",
      "Epoch 40/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 576ms/step - accuracy: 0.9923 - loss: 0.0501 - precision: 0.9935 - recall: 0.9888 - val_accuracy: 0.8621 - val_loss: 1.1182 - val_precision: 0.8810 - val_recall: 0.8506\n",
      "Epoch 41/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 575ms/step - accuracy: 0.9808 - loss: 0.0773 - precision: 0.9868 - recall: 0.9654 - val_accuracy: 0.8621 - val_loss: 1.1029 - val_precision: 0.8706 - val_recall: 0.8506\n",
      "Epoch 42/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 568ms/step - accuracy: 0.9703 - loss: 0.0665 - precision: 0.9839 - recall: 0.9703 - val_accuracy: 0.8621 - val_loss: 1.0780 - val_precision: 0.8605 - val_recall: 0.8506\n",
      "Epoch 43/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 571ms/step - accuracy: 0.9696 - loss: 0.0836 - precision: 0.9847 - recall: 0.9530 - val_accuracy: 0.8161 - val_loss: 1.6757 - val_precision: 0.8161 - val_recall: 0.8161\n",
      "Epoch 44/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 573ms/step - accuracy: 0.9692 - loss: 0.0632 - precision: 0.9783 - recall: 0.9665 - val_accuracy: 0.8046 - val_loss: 1.6213 - val_precision: 0.8193 - val_recall: 0.7816\n",
      "Epoch 45/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 562ms/step - accuracy: 0.9741 - loss: 0.0890 - precision: 0.9752 - recall: 0.9741 - val_accuracy: 0.8966 - val_loss: 1.2890 - val_precision: 0.9070 - val_recall: 0.8966\n",
      "Epoch 46/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 560ms/step - accuracy: 0.9880 - loss: 0.0409 - precision: 0.9962 - recall: 0.9834 - val_accuracy: 0.8736 - val_loss: 1.3703 - val_precision: 0.8837 - val_recall: 0.8736\n",
      "Epoch 47/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 577ms/step - accuracy: 0.9825 - loss: 0.0592 - precision: 0.9822 - recall: 0.9732 - val_accuracy: 0.8621 - val_loss: 1.5118 - val_precision: 0.8588 - val_recall: 0.8391\n",
      "Epoch 48/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 566ms/step - accuracy: 0.9938 - loss: 0.0182 - precision: 1.0000 - recall: 0.9910 - val_accuracy: 0.8736 - val_loss: 1.6022 - val_precision: 0.8810 - val_recall: 0.8506\n",
      "Epoch 49/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 574ms/step - accuracy: 0.9818 - loss: 0.0481 - precision: 1.0000 - recall: 0.9725 - val_accuracy: 0.8851 - val_loss: 1.6248 - val_precision: 0.8953 - val_recall: 0.8851\n",
      "Epoch 50/50\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 569ms/step - accuracy: 0.9984 - loss: 0.0252 - precision: 0.9984 - recall: 0.9952 - val_accuracy: 0.8736 - val_loss: 1.6328 - val_precision: 0.8824 - val_recall: 0.8621\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_one_hot, epochs = 50, validation_data = (X_test, y_test_one_hot), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98c4345b-1669-4653-bfb5-e839500bfa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 573ms/step - accuracy: 0.9972 - loss: 0.0289 - precision: 0.9972 - recall: 0.9880 - val_accuracy: 0.8736 - val_loss: 1.6789 - val_precision: 0.8837 - val_recall: 0.8736\n",
      "Epoch 2/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 565ms/step - accuracy: 0.9807 - loss: 0.0483 - precision: 0.9807 - recall: 0.9762 - val_accuracy: 0.8506 - val_loss: 1.7821 - val_precision: 0.8605 - val_recall: 0.8506\n",
      "Epoch 3/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 567ms/step - accuracy: 0.9838 - loss: 0.0572 - precision: 0.9880 - recall: 0.9761 - val_accuracy: 0.8276 - val_loss: 1.8190 - val_precision: 0.8554 - val_recall: 0.8161\n",
      "Epoch 4/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 557ms/step - accuracy: 0.9694 - loss: 0.0995 - precision: 0.9729 - recall: 0.9694 - val_accuracy: 0.8046 - val_loss: 1.6588 - val_precision: 0.8235 - val_recall: 0.8046\n",
      "Epoch 5/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 558ms/step - accuracy: 0.9698 - loss: 0.0676 - precision: 0.9767 - recall: 0.9698 - val_accuracy: 0.7701 - val_loss: 1.7595 - val_precision: 0.7765 - val_recall: 0.7586\n",
      "Epoch 6/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 566ms/step - accuracy: 0.9847 - loss: 0.0396 - precision: 0.9956 - recall: 0.9847 - val_accuracy: 0.8391 - val_loss: 2.1852 - val_precision: 0.8471 - val_recall: 0.8276\n",
      "Epoch 7/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 554ms/step - accuracy: 0.9729 - loss: 0.0771 - precision: 0.9815 - recall: 0.9683 - val_accuracy: 0.8276 - val_loss: 2.4725 - val_precision: 0.8471 - val_recall: 0.8276\n",
      "Epoch 8/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 563ms/step - accuracy: 0.9840 - loss: 0.0334 - precision: 0.9944 - recall: 0.9794 - val_accuracy: 0.7816 - val_loss: 2.8324 - val_precision: 0.7765 - val_recall: 0.7586\n",
      "Epoch 9/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 561ms/step - accuracy: 0.9740 - loss: 0.0555 - precision: 0.9800 - recall: 0.9740 - val_accuracy: 0.7586 - val_loss: 2.3933 - val_precision: 0.7765 - val_recall: 0.7586\n",
      "Epoch 10/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 569ms/step - accuracy: 0.9838 - loss: 0.0693 - precision: 0.9838 - recall: 0.9838 - val_accuracy: 0.7701 - val_loss: 2.0652 - val_precision: 0.7701 - val_recall: 0.7701\n",
      "Epoch 11/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 573ms/step - accuracy: 0.9874 - loss: 0.0674 - precision: 0.9874 - recall: 0.9862 - val_accuracy: 0.8161 - val_loss: 1.8817 - val_precision: 0.8161 - val_recall: 0.8161\n",
      "Epoch 12/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 562ms/step - accuracy: 0.9817 - loss: 0.0692 - precision: 0.9852 - recall: 0.9817 - val_accuracy: 0.8276 - val_loss: 1.7188 - val_precision: 0.8333 - val_recall: 0.8046\n",
      "Epoch 13/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 566ms/step - accuracy: 0.9873 - loss: 0.0684 - precision: 0.9873 - recall: 0.9873 - val_accuracy: 0.7931 - val_loss: 1.9022 - val_precision: 0.8023 - val_recall: 0.7931\n",
      "Epoch 14/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 566ms/step - accuracy: 0.9848 - loss: 0.0493 - precision: 0.9863 - recall: 0.9812 - val_accuracy: 0.8391 - val_loss: 1.9431 - val_precision: 0.8452 - val_recall: 0.8161\n",
      "Epoch 15/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 570ms/step - accuracy: 0.9938 - loss: 0.0164 - precision: 0.9938 - recall: 0.9938 - val_accuracy: 0.7931 - val_loss: 1.9030 - val_precision: 0.8072 - val_recall: 0.7701\n",
      "Epoch 16/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 564ms/step - accuracy: 1.0000 - loss: 0.0106 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.8046 - val_loss: 2.0951 - val_precision: 0.8046 - val_recall: 0.8046\n",
      "Epoch 17/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 566ms/step - accuracy: 0.9861 - loss: 0.0436 - precision: 0.9882 - recall: 0.9861 - val_accuracy: 0.8161 - val_loss: 1.8496 - val_precision: 0.8161 - val_recall: 0.8161\n",
      "Epoch 18/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 575ms/step - accuracy: 0.9899 - loss: 0.0232 - precision: 0.9926 - recall: 0.9899 - val_accuracy: 0.7701 - val_loss: 1.7740 - val_precision: 0.7882 - val_recall: 0.7701\n",
      "Epoch 19/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 568ms/step - accuracy: 0.9954 - loss: 0.0163 - precision: 0.9954 - recall: 0.9954 - val_accuracy: 0.8391 - val_loss: 1.7262 - val_precision: 0.8488 - val_recall: 0.8391\n",
      "Epoch 20/20\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 567ms/step - accuracy: 0.9977 - loss: 0.0221 - precision: 0.9988 - recall: 0.9977 - val_accuracy: 0.8506 - val_loss: 1.7462 - val_precision: 0.8605 - val_recall: 0.8506\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_one_hot, epochs = 20, validation_data = (X_test, y_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e67c9114-0323-4ab3-8e73-e94adb52cb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8667 - loss: 1.1163 - precision: 0.8716 - recall: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7461644411087036,\n",
       " 0.8505747318267822,\n",
       " 0.8604651093482971,\n",
       " 0.8505747318267822]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18136ce5-9389-4298-becf-cfd0c6db4951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "y6,sr = librosa.load('IMG_1860.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1e55c23-074a-4936-9465-5e18c8bd80d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Sad\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "if np.argmax(model.predict(y6[:28618].reshape(1,28618,-1))) == 1:\n",
    "    print('Sad')\n",
    "elif np.argmax(model.predict(y6[:28618].reshape(1,28618,-1))) == 2:\n",
    "    print('Angry')\n",
    "elif np.argmax(model.predict(y6[:28618].reshape(1,28618,-1))) == 3:\n",
    "    print('Disgust')\n",
    "elif np.argmax(model.predict(y6[:28618].reshape(1,28618,-1))) == 4:\n",
    "    print('Fear')\n",
    "elif np.argmax(model.predict(y6[:28618].reshape(1,28618,-1))) == 5:\n",
    "    print('Happy')\n",
    "elif np.argmax(model.predict(y6[:28618].reshape(1,28618,-1))) == 6:\n",
    "    print('Neutral')\n",
    "elif np.argmax(model.predict(y6[:28618].reshape(1,28618,-1))) == 0:\n",
    "    print('Pleasently Suprised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b938f-540c-4b39-9865-d5737c236a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c37977-a57a-4590-ad73-38b4493e917b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de34054-3e82-42a6-9bc8-ac7e98a1a33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b4a76-c622-4180-aebb-2d22c0372a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc75230-c2f3-4903-bb24-b3736b18ad23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6f5fc-9b09-4cfc-b604-43d141abe51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4fcfe4df-9d58-47b1-8d2d-eea8419ffd45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1dbf091-5f53-4bd8-9b59-c34d64f15cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10fcbd1f-8b00-406b-8a36-5e7771dabd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28608</th>\n",
       "      <th>28609</th>\n",
       "      <th>28610</th>\n",
       "      <th>28611</th>\n",
       "      <th>28612</th>\n",
       "      <th>28613</th>\n",
       "      <th>28614</th>\n",
       "      <th>28615</th>\n",
       "      <th>28616</th>\n",
       "      <th>28617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.011831</td>\n",
       "      <td>0.011495</td>\n",
       "      <td>0.011328</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>0.010341</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.009870</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.009183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006806</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.001320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000214</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023106</td>\n",
       "      <td>0.022516</td>\n",
       "      <td>0.022223</td>\n",
       "      <td>0.022654</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>0.020769</td>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.019982</td>\n",
       "      <td>0.019488</td>\n",
       "      <td>0.019479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011752</td>\n",
       "      <td>-0.012834</td>\n",
       "      <td>-0.013127</td>\n",
       "      <td>-0.014145</td>\n",
       "      <td>-0.014910</td>\n",
       "      <td>-0.014972</td>\n",
       "      <td>-0.015022</td>\n",
       "      <td>-0.015133</td>\n",
       "      <td>-0.014588</td>\n",
       "      <td>-0.014221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072800</td>\n",
       "      <td>-0.024119</td>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.067527</td>\n",
       "      <td>0.097443</td>\n",
       "      <td>0.112806</td>\n",
       "      <td>0.108192</td>\n",
       "      <td>0.094044</td>\n",
       "      <td>0.069962</td>\n",
       "      <td>0.035311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014960</td>\n",
       "      <td>-0.012262</td>\n",
       "      <td>-0.009535</td>\n",
       "      <td>-0.006317</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.002139</td>\n",
       "      <td>-0.000373</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>-0.000954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029587</td>\n",
       "      <td>-0.048441</td>\n",
       "      <td>-0.071518</td>\n",
       "      <td>-0.089924</td>\n",
       "      <td>-0.092331</td>\n",
       "      <td>-0.081464</td>\n",
       "      <td>-0.066608</td>\n",
       "      <td>-0.049403</td>\n",
       "      <td>-0.032738</td>\n",
       "      <td>-0.010862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>-0.001665</td>\n",
       "      <td>-0.008384</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>-0.005616</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>-0.004280</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.009111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007540</td>\n",
       "      <td>-0.003894</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.013843</td>\n",
       "      <td>0.017601</td>\n",
       "      <td>0.018078</td>\n",
       "      <td>0.016734</td>\n",
       "      <td>0.013838</td>\n",
       "      <td>0.008255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>-0.000423</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.000555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>-0.006302</td>\n",
       "      <td>-0.010737</td>\n",
       "      <td>-0.009139</td>\n",
       "      <td>-0.011463</td>\n",
       "      <td>-0.013268</td>\n",
       "      <td>-0.015042</td>\n",
       "      <td>-0.017226</td>\n",
       "      <td>-0.018437</td>\n",
       "      <td>-0.017241</td>\n",
       "      <td>-0.016195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.009922</td>\n",
       "      <td>-0.009082</td>\n",
       "      <td>-0.017726</td>\n",
       "      <td>-0.004442</td>\n",
       "      <td>-0.001394</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.014722</td>\n",
       "      <td>-0.001913</td>\n",
       "      <td>-0.025608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows × 28618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6      \\\n",
       "0    0.000118  0.000121 -0.000252 -0.000133 -0.000222 -0.000144  0.000038   \n",
       "1    0.000012  0.000147  0.000083  0.000050  0.000033  0.000119  0.000231   \n",
       "2   -0.000214  0.000361  0.000543  0.000181  0.000109  0.000486  0.000797   \n",
       "3    0.000002  0.000003  0.000110  0.000059  0.000053  0.000101  0.000084   \n",
       "4    0.000013  0.000258  0.000628  0.001070  0.000962  0.001304  0.001649   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "256 -0.000017 -0.000075 -0.000086 -0.000156 -0.000163 -0.000193 -0.000143   \n",
       "257  0.000539  0.000162 -0.000542 -0.000187 -0.000074 -0.000125  0.000432   \n",
       "258 -0.001665 -0.008384  0.004194  0.000980 -0.005616  0.000439 -0.004280   \n",
       "259  0.002500  0.002617  0.002285  0.003409  0.002544  0.003481  0.003604   \n",
       "260 -0.006302 -0.010737 -0.009139 -0.011463 -0.013268 -0.015042 -0.017226   \n",
       "\n",
       "        7         8         9      ...     28608     28609     28610  \\\n",
       "0    0.000017  0.000111  0.000073  ...  0.011723  0.011831  0.011495   \n",
       "1    0.000133  0.000173  0.000184  ...  0.006806  0.006466  0.005938   \n",
       "2    0.000335  0.000289  0.000393  ...  0.023106  0.022516  0.022223   \n",
       "3    0.000119  0.000073  0.000162  ... -0.011752 -0.012834 -0.013127   \n",
       "4    0.001880  0.002199  0.001998  ... -0.072800 -0.024119  0.023734   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "256 -0.000136 -0.000140 -0.000133  ... -0.014960 -0.012262 -0.009535   \n",
       "257 -0.000281 -0.000788 -0.000954  ... -0.029587 -0.048441 -0.071518   \n",
       "258  0.002679 -0.001823 -0.009111  ... -0.007540 -0.003894  0.001745   \n",
       "259  0.002303  0.002614  0.002248  ... -0.000411  0.000178  0.000438   \n",
       "260 -0.018437 -0.017241 -0.016195  ...  0.005500  0.009922 -0.009082   \n",
       "\n",
       "        28611     28612     28613     28614     28615     28616     28617  \n",
       "0    0.011328  0.010618  0.010341  0.010364  0.009870  0.009608  0.009183  \n",
       "1    0.005409  0.004927  0.004478  0.003702  0.002927  0.002131  0.001320  \n",
       "2    0.022654  0.021622  0.020769  0.020250  0.019982  0.019488  0.019479  \n",
       "3   -0.014145 -0.014910 -0.014972 -0.015022 -0.015133 -0.014588 -0.014221  \n",
       "4    0.067527  0.097443  0.112806  0.108192  0.094044  0.069962  0.035311  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "256 -0.006317 -0.004245 -0.002139 -0.000373  0.000441  0.000964  0.001417  \n",
       "257 -0.089924 -0.092331 -0.081464 -0.066608 -0.049403 -0.032738 -0.010862  \n",
       "258  0.008300  0.013843  0.017601  0.018078  0.016734  0.013838  0.008255  \n",
       "259 -0.000085  0.000779  0.001442 -0.000423 -0.000374 -0.000147 -0.000555  \n",
       "260 -0.017726 -0.004442 -0.001394  0.003926  0.014722 -0.001913 -0.025608  \n",
       "\n",
       "[261 rows x 28618 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea92367-67bd-41ac-9d3f-f2be7c84bb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c7411d-7171-4bbb-8384-fdf5ffa89d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6203f-cf68-4082-8019-1f97f576228a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305d0f2-af9b-41b9-bda9-0c721e68b41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b1f6a-09bd-4a78-96e0-9c7f8f38f2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
